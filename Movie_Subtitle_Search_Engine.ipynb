{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ Movie Subtitle Semantic Search Engine\n",
    "\n",
    "This notebook demonstrates semantic search on movie subtitles using TF-IDF vectorization and cosine similarity.\n",
    "\n",
    "## Features:\n",
    "- Load movie subtitle data from SQLite database\n",
    "- Text preprocessing and cleaning\n",
    "- TF-IDF vectorization for semantic understanding\n",
    "- Interactive search functionality\n",
    "- Results ranking by similarity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sqlite3\n",
    "import zipfile\n",
    "import io\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Connection and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database path - uses local file in current directory\n",
    "database_path = \"eng_subtitles_database.db\"\n",
    "\n",
    "# Check if database exists\n",
    "if not os.path.exists(database_path):\n",
    "    print(\"‚ùå Database not found. Make sure 'eng_subtitles_database.db' is in the current directory.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Database found: {database_path}\")\n",
    "\n",
    "# Connect to database and load data\n",
    "try:\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Execute query to get subtitle data\n",
    "    cursor.execute(\"SELECT num, name, content FROM zipfiles\")\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(rows, columns=['subtitle_id', 'subtitle_name', 'subtitle_content'])\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(df)} subtitle files from database\")\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst few entries:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip_content(content):\n",
    "    \"\"\"Extract content from zip files\"\"\"\n",
    "    try:\n",
    "        with io.BytesIO(content) as bio:\n",
    "            with zipfile.ZipFile(bio, \"r\") as zipf:\n",
    "                for file_name in zipf.namelist():\n",
    "                    with zipf.open(file_name) as file:\n",
    "                        text = file.read().decode(\"latin-1\")\n",
    "                        return text\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean subtitle text by removing timestamps and formatting\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove timestamps\n",
    "    text = re.sub(r'\\d{1,2}:\\d{2}:\\d{2},\\d{3} --> \\d{1,2}:\\d{2}:\\d{2},\\d{3}\\r?\\n', '', text)\n",
    "    # Remove line breaks\n",
    "    text = re.sub(r'\\r?\\n', ' ', text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    # Keep only letters and spaces\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Convert to lowercase and strip\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(\"‚úÖ Text processing functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the subtitle content\n",
    "print(\"Processing subtitle content...\")\n",
    "\n",
    "# Extract zip content\n",
    "print(\"  Extracting zip files...\")\n",
    "df['subtitle_content'] = df['subtitle_content'].apply(extract_zip_content)\n",
    "\n",
    "# Clean text\n",
    "print(\"  Cleaning text...\")\n",
    "df['subtitle_content'] = df['subtitle_content'].apply(clean_text)\n",
    "\n",
    "# Remove empty content\n",
    "df = df[df['subtitle_content'].str.len() > 50]  # Keep only meaningful content\n",
    "\n",
    "# Clean movie names\n",
    "df['subtitle_name'] = df['subtitle_name'].str.replace('.', ' ', regex=False)\n",
    "df['subtitle_name'] = df['subtitle_name'].str.replace('eng 1cd', '', regex=False).str.strip()\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f\"‚úÖ Processed {len(df)} movies with meaningful content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display processed data\n",
    "print(\"Processed Data Sample:\")\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"\\n{i+1}. Movie: {df.iloc[i]['subtitle_name'].title()}\")\n",
    "    print(f\"   Content Preview: {df.iloc[i]['subtitle_content'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Search Index with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "print(\"Creating TF-IDF search index...\")\n",
    "\n",
    "# Extract documents for vectorization\n",
    "documents = df['subtitle_content'].tolist()\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,      # Limit vocabulary size\n",
    "    stop_words='english',   # Remove common English words\n",
    "    ngram_range=(1, 2),     # Use both single words and pairs\n",
    "    min_df=1,               # Minimum document frequency\n",
    "    max_df=0.8              # Maximum document frequency\n",
    ")\n",
    "\n",
    "# Fit and transform documents\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(f\"‚úÖ TF-IDF matrix created with shape: {tfidf_matrix.shape}\")\n",
    "print(f\"   Vocabulary size: {len(vectorizer.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_movies(query, top_k=5):\n",
    "    \"\"\"Search for movies using semantic similarity\"\"\"\n",
    "    # Transform query using the same vectorizer\n",
    "    query_vector = vectorizer.transform([query.lower()])\n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Get top results\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    results = []\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        if similarities[idx] > 0:  # Only return relevant results\n",
    "            results.append({\n",
    "                'rank': i + 1,\n",
    "                'movie': df.iloc[idx]['subtitle_name'].title(),\n",
    "                'similarity': round(similarities[idx], 3),\n",
    "                'content_preview': df.iloc[idx]['subtitle_content'][:200] + \"...\"\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def display_results(results, query):\n",
    "    \"\"\"Display search results in a formatted way\"\"\"\n",
    "    print(f\"\\nüîç Search Results for: '{query}'\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No relevant results found.\")\n",
    "        return\n",
    "    \n",
    "    for result in results:\n",
    "        print(f\"\\n{result['rank']}. {result['movie']}\")\n",
    "        print(f\"   Similarity Score: {result['similarity']}\")\n",
    "        print(f\"   Content: \\\"{result['content_preview']}\\\"\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "print(\"‚úÖ Search functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different types of queries\n",
    "test_queries = [\n",
    "    \"betrayal by friend\",\n",
    "    \"life is like chocolates\",\n",
    "    \"drunk party night\",\n",
    "    \"force with you\",\n",
    "    \"never let go\"\n",
    "]\n",
    "\n",
    "print(\"üé¨ Testing Semantic Search with Different Queries\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for query in test_queries:\n",
    "    results = search_movies(query, top_k=3)\n",
    "    display_results(results, query)\n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive search function\n",
    "def interactive_search():\n",
    "    \"\"\"Run interactive search session\"\"\"\n",
    "    print(\"\\nüéØ Interactive Movie Search\")\n",
    "    print(\"Enter your search queries. Type 'quit' to exit.\")\n",
    "    print(\"\\nExample queries:\")\n",
    "    print(\"- 'betrayal by friend'\")\n",
    "    print(\"- 'life wisdom advice'\")\n",
    "    print(\"- 'love scene romantic'\")\n",
    "    print(\"- 'drunk party night'\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nüîç Enter search query: \").strip()\n",
    "            \n",
    "            if query.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"Thanks for testing! üëã\")\n",
    "                break\n",
    "                \n",
    "            if not query:\n",
    "                print(\"Please enter a search query.\")\n",
    "                continue\n",
    "                \n",
    "            results = search_movies(query, top_k=3)\n",
    "            display_results(results, query)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nSearch session ended.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "# Uncomment the line below to start interactive search\n",
    "# interactive_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the vocabulary and most important terms\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_scores = tfidf_matrix.sum(axis=0).A1\n",
    "\n",
    "# Get top terms by TF-IDF score\n",
    "top_terms_idx = tfidf_scores.argsort()[-20:][::-1]\n",
    "top_terms = [(feature_names[i], tfidf_scores[i]) for i in top_terms_idx]\n",
    "\n",
    "print(\"üìä Top 20 Terms by TF-IDF Score:\")\n",
    "for i, (term, score) in enumerate(top_terms):\n",
    "    print(f\"{i+1:2d}. {term:15} (score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity scores distribution\n",
    "sample_query = \"love and friendship\"\n",
    "query_vector = vectorizer.transform([sample_query.lower()])\n",
    "similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(similarities, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title(f'Distribution of Similarity Scores for Query: \"{sample_query}\"')\n",
    "plt.xlabel('Cosine Similarity Score')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Statistics for query '{sample_query}':\")\n",
    "print(f\"Mean similarity: {similarities.mean():.3f}\")\n",
    "print(f\"Max similarity: {similarities.max():.3f}\")\n",
    "print(f\"Movies with similarity > 0: {(similarities > 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ Movie Subtitle Semantic Search Engine - Summary\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"‚úÖ Successfully processed {len(df)} movie subtitle files\")\n",
    "print(f\"‚úÖ Created TF-IDF search index with {tfidf_matrix.shape[1]} features\")\n",
    "print(f\"‚úÖ Implemented semantic search using cosine similarity\")\n",
    "print(f\"‚úÖ Tested with multiple query types\")\n",
    "\n",
    "print(\"\\nüöÄ Key Features:\")\n",
    "print(\"   ‚Ä¢ Semantic understanding (finds meaning, not just keywords)\")\n",
    "print(\"   ‚Ä¢ Fast TF-IDF based similarity search\")\n",
    "print(\"   ‚Ä¢ Robust text preprocessing\")\n",
    "print(\"   ‚Ä¢ Interactive search capability\")\n",
    "print(\"   ‚Ä¢ Similarity scoring and ranking\")\n",
    "\n",
    "print(\"\\nüéØ Perfect for:\")\n",
    "print(\"   ‚Ä¢ Finding movies by theme or emotion\")\n",
    "print(\"   ‚Ä¢ Content discovery based on dialogue\")\n",
    "print(\"   ‚Ä¢ Semantic similarity analysis\")\n",
    "print(\"   ‚Ä¢ Natural language movie search\")\n",
    "\n",
    "print(\"\\nüìã Technical Stack:\")\n",
    "print(\"   ‚Ä¢ Python + pandas for data processing\")\n",
    "print(\"   ‚Ä¢ scikit-learn for TF-IDF vectorization\")\n",
    "print(\"   ‚Ä¢ SQLite for data storage\")\n",
    "print(\"   ‚Ä¢ Regular expressions for text cleaning\")\n",
    "print(\"   ‚Ä¢ Cosine similarity for semantic matching\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}